{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import scipy.sparse as sp\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class def_episode:\n",
    "    def __init__(self, evnts, edge_set):#, lastevnt, pred, succ):\n",
    "        self.freq = 0\n",
    "        self.evnts = evnts.copy()\n",
    "        self.edges = edge_set.copy()\n",
    "#         self.lastevnt = lastevnt\n",
    "#         self.pred = pred.copy()\n",
    "#         self.succ = succ.copy()\n",
    "\n",
    "class def_NFA:\n",
    "    def __init__(self):\n",
    "        self.s = set()\n",
    "        self.S = list([self.s])\n",
    "        self.F = -1\n",
    "        self.D = {}\n",
    "\n",
    "class def_DFA:\n",
    "    def __init__(self):\n",
    "        self.s = {0}\n",
    "        self.S = list([self.s])\n",
    "        self.F = list()\n",
    "        self.D = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Construct_NFA(alpha):\n",
    "    alpha_size = len(alpha.evnts)\n",
    "    pi = {}\n",
    "    for e in alpha.evnts:\n",
    "        pi[e] = set()\n",
    "    for (e1,e2) in alpha.edges:\n",
    "        pi[e2].add(e1)\n",
    "    NFA = def_NFA()\n",
    "    n_states = 1\n",
    "    for Q in NFA.S:\n",
    "        NFA.D[str(Q)] = {}\n",
    "        if len(Q) != alpha_size:\n",
    "            for ev in alpha.evnts-Q:\n",
    "                if not (alpha.evnts-Q).intersection(pi[ev]):\n",
    "                    Q_new = Q.copy()\n",
    "                    Q_new.add(ev)\n",
    "                    if Q_new in NFA.S:\n",
    "                        NFA.D[str(Q)][ev] = {NFA.S.index(Q_new)}\n",
    "                    else:\n",
    "                        NFA.S.append(Q_new)\n",
    "                        NFA.D[str(Q)][ev] = {len(NFA.S)-1}\n",
    "#                     NFA.D[str(Q)][ev] = [Q_new]\n",
    "#                     if Q_new not in NFA.S:\n",
    "#                         NFA.S.append(Q_new)\n",
    "            NFA.D[str(Q)]['def'] = {NFA.S.index(Q)}\n",
    "        else:\n",
    "            NFA.D[str(Q)]['def'] = set()\n",
    "            NFA.F = NFA.S.index(Q)\n",
    "    for ev in alpha.evnts:\n",
    "        if not alpha.evnts.intersection(pi[ev]):\n",
    "            NFA.D[str(NFA.s)][ev].add(0)\n",
    "    return NFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Construct_DFA(NFA):\n",
    "    DFA = def_DFA()\n",
    "    for state in DFA.S:\n",
    "        if (NFA.F in state):\n",
    "            DFA.F.append(state)\n",
    "        DFA.D[str(state)] = {}\n",
    "        W = set({})\n",
    "        for substate in state:\n",
    "            Q = str(NFA.S[substate])\n",
    "            W = W.union(set(NFA.D[Q].keys()))\n",
    "        for ev in W:\n",
    "            new_state = set()\n",
    "            for substate in state:\n",
    "                Q = str(NFA.S[substate])\n",
    "                if ev in NFA.D[Q].keys():\n",
    "                    new_state = new_state.union(NFA.D[Q][ev])\n",
    "#                     DFA.D[str(state)][ev] = DFA.D[str(state)][ev].union(NFA.D[Q][ev])\n",
    "                else:\n",
    "                    new_state = new_state.union(NFA.D[Q]['def'])\n",
    "#                     DFA.D[str(state)][ev] = DFA.D[str(state)][ev].union(NFA.D[Q]['def'])\n",
    "            DFA.D[str(state)][ev] = new_state.copy()\n",
    "            if new_state not in DFA.S:\n",
    "                        DFA.S.append(new_state)\n",
    "        keys = list(DFA.D[str(state)].keys())\n",
    "        for k in range(len(keys)):\n",
    "            if keys[k] != 'def' and DFA.D[str(state)][keys[k]] == DFA.D[str(state)]['def']:\n",
    "                del DFA.D[str(state)][keys[k]]\n",
    "            else:\n",
    "                k += 1\n",
    "    return DFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "episodes = list([])\n",
    "\n",
    "N = 4\n",
    "episodes.append(def_episode(set({'1','2','3','4'}),set({('1','2'),('1','3'),('1','4'),('2','3'),('2','4'),('3','4')})))\n",
    "episodes.append(def_episode(set({'5','6','7','8'}),set({('5','6'),('5','7'),('5','8'),('6','7'),('6','8'),('7','8')})))\n",
    "\n",
    "# N = 6\n",
    "# episodes.append(def_episode(set({'1','2','3','4','5','6'}),set({('1','2'),('1','3'),('1','4'),('1','5'),('1','6'),('2','3'),('2','4'),('2','5'),('2','6'),('3','4'),('3','5'),('3','6'),('4','5'),('4','6'),('5','6')})))\n",
    "# episodes.append(def_episode(set({'7','8','9','10','11','12'}),set({('7','8'),('7','9'),('7','10'),('7','11'),('7','12'),('8','9'),('8','10'),('8','11'),('8','12'),('9','10'),('9','11'),('9','12'),('10','11'),('10','12'),('11','12')})))\n",
    "\n",
    "\n",
    "NFA = list()\n",
    "DFA = list()\n",
    "\n",
    "\n",
    "\n",
    "final_states = list()\n",
    "\n",
    "for episode in episodes:\n",
    "    NFA.append(Construct_NFA(episode))\n",
    "    DFA.append(Construct_DFA(NFA[-1]))\n",
    "    \n",
    "    final_states.append(set())\n",
    "    for k in range(len(DFA[-1].S)):\n",
    "        if (NFA[-1].F in DFA[-1].S[k]):\n",
    "            final_states[-1].add(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "M = 50\n",
    "T = 10000\n",
    "\n",
    "qn = 0.7\n",
    "qe = 0\n",
    "\n",
    "pe = 1/M\n",
    "\n",
    "curr_state = list([])\n",
    "for k in range(len(episodes)):\n",
    "    curr_state.append({0})\n",
    "\n",
    "noise_flag = True\n",
    "count = [0]*len(episodes)\n",
    "\n",
    "datastream = list([])\n",
    "for t in range(1,T+1):\n",
    "    num = rd.uniform(0,1)\n",
    "    \n",
    "    if noise_flag:\n",
    "        if num > qn:\n",
    "            noise_flag = False\n",
    "    else:\n",
    "        if num > qe:\n",
    "            noise_flag = True\n",
    "    \n",
    "    if noise_flag:\n",
    "        datastream.append((str(rd.sample(range(1,M+1),1)[0]),t))\n",
    "    else:\n",
    "        ep_id = rd.sample(range(len(episodes)),1)[0]\n",
    "        state = curr_state[ep_id]\n",
    "        nextevents = list(DFA[ep_id].D[str(state)].keys())\n",
    "        if NFA[ep_id].F not in state:\n",
    "            nextevents.remove('def')\n",
    "            new_event = rd.sample(nextevents,1)[0]\n",
    "            datastream.append((new_event,t))\n",
    "            curr_state[ep_id] = DFA[ep_id].D[str(state)][new_event]\n",
    "        else:\n",
    "            count[ep_id] += 1\n",
    "            probs = list([])\n",
    "            for nxtevnt in nextevents:\n",
    "                if nxtevnt == 'def':\n",
    "                    probs.append(1-pe*(len(nextevents)-1))\n",
    "                else:\n",
    "                    probs.append(pe)\n",
    "            new_event = rd.choices(nextevents, probs, k=1)[0]\n",
    "            if new_event != 'def':\n",
    "                datastream.append((new_event,t))\n",
    "                curr_state[ep_id] = DFA[ep_id].D[str(state)][new_event]\n",
    "            else:\n",
    "                oncemore = True\n",
    "                while oncemore:\n",
    "                    temp = str(rd.sample(range(1,M+1),1)[0])\n",
    "                    if temp not in episodes[ep_id].evnts:\n",
    "                        oncemore = False\n",
    "                datastream.append((temp,t))\n",
    "                curr_state[ep_id] = DFA[ep_id].D[str(state)][new_event]\n",
    "print('No of occurrences of episodes embedded:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'Data/Datastream_M_'+ str(M) + '_n_'+ str(T) + '_N_'+ str(N) + '_emb_' + str(len(episodes)) + '_q1_' + str(qn) + '_q2_' + str(qe) + '_set_0.txt'\n",
    "with open(name,'w') as f:\n",
    "\n",
    "    for (e,t) in datastream:\n",
    "        f.write(e + ',' + str(t) + '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
